{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Evaluate_Project_Capex_And_Materiality.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMJGC_c3rd0F"
      },
      "source": [
        "<h1>Colab Python Notebook For How Banks Can Save The World Pt 2</h1>\n",
        "\n",
        "<h2>Applies Electra NLP model to company reports to identify projects funded by this organisation</h2>\n",
        "\n",
        "Downloads tensorflow based NLP model 'electra' fine tuned for Q&A\n",
        "\n",
        "Uses excerpts from company reports as context - question panel designed to pick the names of projects and initiatives that the company is funding.\n",
        "\n",
        "The model produces an nbest file (not shown in this notebook - an exceprt will be uploaded to git hub) which contains any projects and initiatives that the company may be funding. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPjXjWRarklP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29198abc-9bfc-43be-a5cc-4b2b27a6896b"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDot8ZSQrlKF",
        "outputId": "766015d2-999d-4244-f5ef-83610ecd19c2"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "import tensorflow.compat.v1 as tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVvntHaEslrY",
        "outputId": "929cd7ce-2717-41fe-b885-c6b769af13a8"
      },
      "source": [
        "!git clone https://github.com/infospark/electra.git\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'electra'...\n",
            "remote: Enumerating objects: 378, done.\u001b[K\n",
            "remote: Total 378 (delta 0), reused 0 (delta 0), pack-reused 378\u001b[K\n",
            "Receiving objects: 100% (378/378), 11.88 MiB | 12.95 MiB/s, done.\n",
            "Resolving deltas: 100% (249/249), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUv7QqizsxvD",
        "outputId": "7fe6d97d-c6ed-43e2-849d-0417cd4b9cdb"
      },
      "source": [
        "cd /content/electra"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/electra\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rp4ow6H8s2MV"
      },
      "source": [
        "# Set up Tensor Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFuhbhfxevhY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc460db9-fd50-4c92-9184-bc3d6216daaa"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjFCC9h0s7DC",
        "outputId": "bc2427ce-58c4-4432-d68f-57464d3eca4b"
      },
      "source": [
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is => ', TPU_ADDRESS)\n",
        "\n",
        "\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is =>  grpc://10.45.224.178:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 14538302335085740752),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 18121934246772018943),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 3350729021359451590),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 5052307395710909598),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 4067832406828410456),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 4716350520594257938),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 14102687750644912418),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 2291278774728361259),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 12048019537555119759),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 7461736245776762503),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 6138889704919666558)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbNxw73q2CnJ",
        "outputId": "b627a487-b6f5-4156-ce54-56d061917231"
      },
      "source": [
        "%%writefile dev.json\n",
        "{\n",
        "    \"version\": \"v2.0\",\n",
        "    \"data\": [\n",
        "        {\n",
        "            \"title\": \"Project Identification\",\n",
        "            \"paragraphs\": [\n",
        "                {\n",
        "                    \"qas\": [\n",
        "                        {\n",
        "                            \"question\": \"What initiative is in progress?\",\n",
        "                            \"id\": \"q_initiative\",\n",
        "                            \"answers\": [],\n",
        "                            \"is_impossible\": false\n",
        "                        },{\n",
        "                            \"question\": \"What project is being funded?\",\n",
        "                            \"id\": \"q_funded\",\n",
        "                            \"answers\": [],\n",
        "                            \"is_impossible\": false\n",
        "                        },{\n",
        "                            \"question\": \"What system is being evaluated?\",\n",
        "                            \"id\": \"q_evaluated\",\n",
        "                            \"answers\": [],\n",
        "                            \"is_impossible\": false\n",
        "                        },{\n",
        "                            \"question\": \"What new products are being developed?\",\n",
        "                            \"id\": \"q_new_products\",\n",
        "                            \"answers\": [],\n",
        "                            \"is_impossible\": false\n",
        "                        }\n",
        "                    ],\n",
        "                    \"context\": \"LafargeHolcim’s wide range of low-carbon products (Ductal®, Chronolia®, Agilia®, Artevia®, or Thermedia 6B® for example) enables to reduce both CO2 emissions generated by the production process and CO2 emissions for our clients in the building sector. Furthermore, we are developing with our fundamental research centre new products with higher CO2 savings potential (eg. Aether (30% lower in CO2) or Solidia with a potential up to 70% CO2 reduction). Please note the 11 % revenue refers to the total percentage of sustainable Solutions in 2018. \"\n",
        "\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing dev.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsF6ePwejMQX",
        "outputId": "ff4bcdb6-4e23-4bb6-fa8c-9ded4a136f0a"
      },
      "source": [
        "!gsutil mv dev.json gs://jims_bert_test/electra_data_large/finetuning_data/squad/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://dev.json [Content-Type=application/json]...\n",
            "Removing file://dev.json...\n",
            "\n",
            "Operation completed over 1 objects/1.8 KiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8Nw8JHZs9vU",
        "outputId": "a9d8eeb2-cb6f-4dc8-b3dc-0de287feb8da"
      },
      "source": [
        "!git pull\n",
        "!gsutil rm gs://jims_bert_test/electra_data_large/models/electra_large/finetuning_tfrecords/squad_tfrecords/squad_dev.*\n",
        "!python3 run_finetuning.py --data-dir gs://jims_bert_test/electra_data_large/ --model-name electra_large --hparams '{\"tpu_name\": \"grpc://10.45.224.178:8470\", \"do_train\": false, \"do_eval\": true, \"model_size\": \"large\", \"task_names\": [\"squad\"], \"init_checkpoint\": \"gs://jims_bert_test/electra_data_large/models/electra_large/finetuning_models/squad_model_1\", \"use_tpu\": \"True\", \"num_tpu_cores\":8}'\n",
        "#!python3 run_finetuning.py --data-dir gs://jims_bert_test/electra_data/ --model-name electra_base --hparams '{\"do_train\": false, \"do_eval\": true, \"model_size\": \"base\", \"task_names\": [\"squad\"], \"init_checkpoint\": \"gs://jims_bert_test/electra_data/models/electra_base/finetuning_models/squad_model_1\", \"use_tpu\": \"False\"}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n",
            "Removing gs://jims_bert_test/electra_data_large/models/electra_large/finetuning_tfrecords/squad_tfrecords/squad_dev.metadata...\n",
            "Removing gs://jims_bert_test/electra_data_large/models/electra_large/finetuning_tfrecords/squad_tfrecords/squad_dev.tfrecord...\n",
            "/ [2 objects]                                                                   \n",
            "Operation completed over 2 objects.                                              \n",
            "================================================================================\n",
            "Config: model=electra_large, trial 1/1\n",
            "================================================================================\n",
            "answerable_classifier True\n",
            "answerable_uses_start_logits True\n",
            "answerable_weight 0.5\n",
            "beam_size 20\n",
            "data_dir gs://jims_bert_test/electra_data_large/\n",
            "debug False\n",
            "do_eval True\n",
            "do_lower_case True\n",
            "do_train False\n",
            "doc_stride 128\n",
            "double_unordered True\n",
            "embedding_size None\n",
            "eval_batch_size 32\n",
            "exact_file <built-in method format of str object at 0x7ff7e93e98a0>\n",
            "f1_file <built-in method format of str object at 0x7ff7e93e9930>\n",
            "gcp_project None\n",
            "init_checkpoint gs://jims_bert_test/electra_data_large/models/electra_large/finetuning_models/squad_model_1\n",
            "iterations_per_loop 1000\n",
            "joint_prediction True\n",
            "keep_all_models True\n",
            "layerwise_lr_decay 0.9\n",
            "learning_rate 5e-05\n",
            "log_examples False\n",
            "max_answer_length 50\n",
            "max_query_length 64\n",
            "max_seq_length 512\n",
            "model_dir gs://jims_bert_test/electra_data_large/models/electra_large/finetuning_models/squad_model\n",
            "model_hparam_overrides {}\n",
            "model_name electra_large\n",
            "model_size large\n",
            "n_best_size 200\n",
            "n_writes_test 5\n",
            "nbest_file <built-in method format of str object at 0x7ff7e93e9810>\n",
            "num_tpu_cores 8\n",
            "num_train_epochs 2.0\n",
            "num_trials 1\n",
            "predict_batch_size 32\n",
            "preprocessed_data_dir gs://jims_bert_test/electra_data_large/models/electra_large/finetuning_tfrecords/squad_tfrecords\n",
            "qa_eval_file <built-in method format of str object at 0x7ff7e93e9660>\n",
            "qa_image_dir <built-in method format of str object at 0x7ff7e93e9a50>\n",
            "qa_na_file <built-in method format of str object at 0x7ff7e93e99c0>\n",
            "qa_na_threshold -2.75\n",
            "qa_preds_file <built-in method format of str object at 0x7ff7e93e96f0>\n",
            "raw_data_dir <built-in method format of str object at 0x7ff7e93f4030>\n",
            "results_pkl gs://jims_bert_test/electra_data_large/models/electra_large/results/squad_results.pkl\n",
            "results_txt gs://jims_bert_test/electra_data_large/models/electra_large/results/squad_results.txt\n",
            "save_checkpoints_steps 1000000\n",
            "task_names ['squad']\n",
            "test_predictions <built-in method format of str object at 0x7ff7e940ba30>\n",
            "tokens_file <built-in method format of str object at 0x7ff7e93e9780>\n",
            "tpu_job_name None\n",
            "tpu_name grpc://10.45.224.178:8470\n",
            "tpu_zone None\n",
            "train_batch_size 32\n",
            "use_tfrecords_if_existing True\n",
            "use_tpu True\n",
            "vocab_file gs://jims_bert_test/electra_data_large/vocab.txt\n",
            "vocab_size 30522\n",
            "warmup_proportion 0.1\n",
            "weight_decay_rate 0.01\n",
            "write_distill_outputs False\n",
            "write_test_outputs False\n",
            "\n",
            "================================================================================\n",
            "Run dev set evaluation: model=electra_large, trial 1/1\n",
            "================================================================================\n",
            "Evaluating squad\n",
            "Loading dataset squad_dev\n",
            "Existing tfrecords not found so creating\n",
            "4 examples created, 0 failures\n",
            "Writing example 0 of 4\n",
            "2021-01-17 13:59:37.089480: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:370] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.\n",
            "2021-01-17 13:59:37.343637: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-01-17 13:59:37.353819: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-01-17 13:59:37.353872: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (2cc07c2067d8): /proc/driver/nvidia/version does not exist\n",
            "Building model...\n",
            "Building complete\n",
            "squad: NoAns_exact: 75.00 - NoAns_f1: 75.00 - NoAns_total: 4.00 - best_exact: 100.00 - best_exact_thresh: 0.00 - best_f1: 100.00 - best_f1_thresh: 0.00 - exact: 75.00 - f1: 75.00 - total: 4.00\n",
            "\n",
            "Writing results to gs://jims_bert_test/electra_data_large/models/electra_large/results/squad_results.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eVePIMGP-mD",
        "outputId": "da16f8fc-4030-48d9-fb3b-0ccd0f5cede9"
      },
      "source": [
        "!gsutil cat gs://jims_bert_test/electra_data_large/models/electra_large/results/squad_qa/squad_null_odds.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"q_initiative\": -2.0232818126678467, \"q_funded\": 6.843087196350098, \"q_evaluated\": 4.941781997680664, \"q_new_products\": -4.185152053833008}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMj6q_7_pxVE"
      },
      "source": [
        "# Sample output from nbest file - the top N answers for each question:\n",
        "\"q_evaluated\": [\n",
        "    {\n",
        "      \"text\": \"Aether\",\n",
        "      \"probability\": [\n",
        "        0\n",
        "      ],\n",
        "      \"start_logit\": -6.888813495635986,\n",
        "      \"end_logit\": -0.6815726161003113,\n",
        "      \"start_index\": 53,\n",
        "      \"end_index\": 53\n",
        "    },\n",
        "    {\n",
        "      \"text\": \"Aether (30% lower in CO2) or Solidia\",\n",
        "      \"probability\": [\n",
        "        1\n",
        "      ],\n",
        "      \"start_logit\": -6.888813495635986,\n",
        "      \"end_logit\": -0.8862883448600769,\n",
        "      \"start_index\": 53,\n",
        "      \"end_index\": 59\n",
        "    },\n",
        "    {\n",
        "      \"text\": \"Solidia\",\n",
        "      \"probability\": [\n",
        "        2\n",
        "      ],\n",
        "      \"start_logit\": -7.253624439239502,\n",
        "      \"end_logit\": -0.7757238745689392,\n",
        "      \"start_index\": 59,\n",
        "      \"end_index\": 59\n",
        "    },"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}